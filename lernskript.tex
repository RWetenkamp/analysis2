\documentclass[11pt,a4paper]{scrartcl}
\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{makeidx}
\usepackage{hyperref}
\usepackage{colortbl}
\usepackage{listings}
\usepackage{chngcntr}
\usepackage{upgreek}
\usepackage{pgfplots}
\pgfplotsset{compat = newest}
\usepackage{amsthm}
\usepackage{ulem}
\usepackage{tikz}
\usepackage{graphicx}
\usetikzlibrary{positioning}
\usepackage{tikz-network}
\usepackage[left=3cm,right=3cm,top=3cm,bottom=3cm]{geometry}

\usepackage[backend=biber, style=alphabetic]{biblatex}
\addbibresource{literature.bib}
\author{Roman Wetenkamp}
\title{Einführung in die mehrdimensionale Differentialrechnung}
\subtitle{Angewandte Mathematik für Informatiker*innen}
\theoremstyle{remark}
\newtheorem{note}{Bemerkung}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{satz}{Satz}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{example}{Beispiel}[section]


\begin{document}
\vspace{3cm}
\maketitle
\begin{center}
\includegraphics[scale=0.7]{DHBW.jpg}
\end{center}
\pagebreak
\tableofcontents
\pagebreak
\section*{Vorwort}
Liebe Leser*innen, \\\\
schwere Brocken schocken trocken, wenn man nicht auf sie gefasst ist. So passt es, weiter zu lesen und zu schreiben, damit offene Fragen nicht mehr offen bleiben. Als wir zu Beginn dieses Semesters den Sprung von der eindimensionalen Analysis hin zur auf einmal so stark mit der Linearen Algebra verknüpften mehrdimensionalen Analysis schaffen sollten, überforderte mich das. Diese Lücke zwischen Analysis 1 und Analysis 2 möchte ich mit diesem Skript adressieren und -- falls möglich -- schließen. Im Gegensatz zu hochprofessionellen Lehrbüchern für Mathematikstudierende versuche ich eher, verständlich und ausführlich genug zu bleiben. Mit Beispielen und Aufgaben versuche ich, euch einen Mehrwert zu bieten und nebenbei wieder uns alle erfolgreich ins nächste Semester aufrücken zu lassen. \\\\
Dieses Skript baue ich wie folgt auf:
\begin{enumerate}
\item Wiederholung wichtiger Grundlagen der linearen Algebra
\item Einführung in die mehrdimensionale Analysis (mit Wiederholung der eindimensionalen Analysis)
\item Anwendungsszenarien
\end{enumerate}
Dort, wo ich es für sinnvoll erachte, sind Hinweise auf weiterführende Materialien wie Bücher oder Videos gegeben. \\\\
\textit{Viel Erfolg!}  \\
\begin{flushright}
Roman Wetenkamp \\
Mannheim, den \today
\end{flushright}  
\vfill
\paragraph{Warnung}
Das Studium an einer Dualen Hochschule unterscheidet sich von dem Studium an Universitäten oder regulären Fachhochschulen insbesondere dadurch, dass aufgrund der Dualität von Theorie und Praxis meist nur die Hälfte der Zeit zur Vermittlung des Stoffes zur Verfügung steht (wenn dann auch intensiver). Daher gehen Sie bitte nicht davon aus, dass Sie dieses Skript ausreichend auf Klausuren in regulären Vollzeitstudiengängen vorbereitet!
\paragraph{Hinweis}
Dieses Dokument ist kein Vorlesungsmaterial, hat nicht den Anspruch auf {Voll}\-{ständigkeit} und enthält mit Sicherheit Fehler. Desweiteren ist es noch lange nicht vollendet (es ist infrage zustellen, ob es das je sein wird), und doch möchte ich Sie ermutigen, beizutragen! Jegliche Fehler, Probleme oder Anmerkungen können Sie mir gerne über das dazugehörige GitHub-Repository unter der URL \url{https://github.com/RWetenkamp/analysis2} zukommen lassen. Danke!
\pagebreak
\part{Grundlagen der Linearen Algebra}
Erinnern wir uns zurück an das erste Semester. Nach einer Einführung in grundlegendste Themen wie Mengen, Relationen und Gruppen widmeten wir uns den eigentlichen Inhalten der linearen Algebra, Vektoren, Vektorräumen, linearen Abbildungen und Matrizen. Dieses Kapitel soll einen ganz rudimentären Überblick geben, um womöglich Vergessenes zurück ins Bewusstsein zu rufen, damit wir daran anschließen können.
\section{Vektoren}
Beginnen wir zunächst mit Vektoren. Ein Vektor wird häufig als ein Pfeil dargestellt, weil er physikalische Größen wie Geschwindigkeiten, Kräfte oder Ausdehnungen beschreibt. Grundästzlich wird in der Physik unterschieden zwischen \textbf{vektoriellen} Größen, also den obigen beispielsweise, und \textbf{skalaren} Größen. Skalare Größen sind diejenigen, die durch eine einzige reelle Zahl angegeben werden, zum Beispiel Temperaturen oder Massen. 
\begin{definition}
Ein $n$-Tupel $(a_1, a_2, ..., a_n) \in \mathbb{R}^{n}$ bezeichnen wir als \textbf{Vektor}. Die reellen Zahlen $a_1, ..., a_n$ heißen \textbf{Koordinaten} oder \textbf{Komponenten} eines Vektors. Wir stellen einen Vektor $a$ als $\vec{a}$ dar.
\end{definition}
Vermutlich werden Sie Vektoren bereits in Ihrer Schulzeit behandelt haben. Sie haben Geraden mit Orts- und Richtungsvektoren beschrieben, mit Geraden Ebenen aufgespannt und darin Abstände zwischen Punkt, Gerade und Ebene berechnet. Dabei werden Sie nicht um die Rechenregeln bei Vektoren herum gekommen sein:
\begin{definition} Seien $\vec{a} = (a_1, a_2, ..., a_n), \vec{b} = (b_1, b_2, ..., b_n)$ zwei Vektoren. Wir definieren die \textbf{Summe} beider Vektoren als
\[\vec{a} + \vec{b} = \left( \begin{matrix} a_1 + b_1 \\ a_2 + b_2 \\ ... \\ a_n + b_n \end{matrix} \right).\]
Ebenso definieren wir die \textbf{Multiplikation} eines Vektors und eines Skalars als
\[ k \cdot \vec{a} = \left( \begin{matrix} k \cdot a_1 \\ k \cdot a_2 \\ ... \\ k \cdot a_n \end{matrix}\right).\]
\end{definition}
Diese beiden Rechenoperationen auf Vektoren benötigen wir, um im Folgenden Vektorräume definieren zu können. Doch zunächst betrachten wir eine weitere Eigenschaft von Vektoren:
\begin{definition}
Die \textbf{Länge} oder der \textbf{Betrag} eines Vektors $\vec{a} \in \mathbb{R}^{n}$ wird definiert durch
\[\Vert \vec{a} \Vert = \sqrt{\sum\limits_{j = 1}^{n} a_{j}^{2}} = \sqrt{a_{1}^{2} + a_{2}^{2} + ... + a_{n}^{2}}\]
\end{definition}
\begin{note}
Der Betrag eines Vektors ist immer eine nichtnegative reelle Zahl und $\Vert \vec{a} \Vert = 0 \Leftrightarrow \vec{a} = 0$
\end{note}
\section{Vektorräume}
\begin{definition}
Sei $\mathbb{K}$ ein beliebiger Körper und $V$ eine Menge mit zwei Verknüpfungen:
\begin{enumerate}
\item \textbf{Vektoraddition}: Je zwei Elementen $\vec{a}, \vec{b} \in V$ wird ein Element $\vec{a} + \vec{b} \in V$ zugeordnet, sodass $(V, +)$ eine kommutative ({\glqq}abelsche{\grqq}) Gruppe wird. Neutrales Element ist dabei der Nullvektor und das zu $\vec{a}$ inverse Element ist $\vec{-a}$.
\item \textbf{Multiplikation mit einem Skalar}: Je einem $\vec{a} \in V$ und einem $k \in \mathbb{K}$ wird ein Element $k \cdot \vec{a} \in V$ (wie oben) zugeordnet.
\end{enumerate}
Dann wird $V$ ein \textbf{$\mathbb{K}$-Vektorraum} genannt.
\end{definition}
Da wir nun Vektoren auch aus anderen Körpern als $\mathbb{R}$ betrachten, genügt unsere Definition der Länge eines Vektors nicht mehr. Vorstellbar wären nun nämlich auch Vektoren eines Vektorraums über einem Restklassenkörper, wo auch andere Vektoren als der Nullvektor die Länge $0$ hätten. Dem begegnen wir, in dem wir eine Funktion dafür definieren.
\begin{definition}
Sei $V$ ein reeller Vektorraum mit einer Funktion $\Vert \cdot \Vert : V \mapsto [0, \infty{)}$. \\Wenn 
\begin{align*}
\Vert \vec{a} \Vert &> 0 \text{ für } \vec{a} \neq 0 \quad &\text{(Positivität)}\\
\Vert k \cdot \vec{a} \Vert &= \vert k \vert \cdot \Vert \vec{a} \Vert & \text{(Homogenität)} \\
\Vert \vec{a} + \vec{b} \Vert &\leq \Vert \vec{a} \Vert + \Vert \vec{b} \Vert & \text{(Dreiecksungleichung)}
\end{align*}
für alle $\vec{a}, \vec{b} \in V$ und $k \in \mathbb{R}$, so nennen wir diese Funktion eine \textbf{Norm} und den Vektorraum $V$ einen \textbf{normierten Raum}.
\end{definition}
Damit hätten wir den Grundstein für weitere Betrachtungen und Definitionen gelegt -- es liegt noch einiges vor uns.

\section{Skalarprodukt}
Im vorherigen Abschnitt haben wir bereits die Multiplikation eines Vektors mit einem Skalar betrachtet. Nun führen wir die Multiplikation zweier Vektoren ein. Nur diese Multiplikation nennen wir \textbf{Skalarmultiplikation}, weil wir als Ergebnis einen Skalar erhalten.
\begin{definition}
Das Produkt zweier Vektoren $\vec{a} = (a_1, a_2, ..., a_n)$ und $\vec{b} = (b_1, b_2, ..., b_n)$ ist definiert durch 
\[\langle \vec{a}, \vec{b} \rangle = \sum\limits_{j=1}^{n}a_j \cdot b_j = a_1 \cdot b_1 + a_2 \cdot b_2 + ... + a_n \cdot b_n\] und wird als \textbf{Skalarprodukt} oder \textbf{inneres Produkt} der beiden Vektoren bezeichnet.
\end{definition}
Das Skalarprodukt verwenden wir nun, um folgenden Zusammenhang festzuhalten:
\begin{satz}
\[\cos ({\phi}) = \frac{\langle \vec{v}, \vec{w}\rangle}{\Vert \vec{v} \Vert \cdot \Vert \vec{w} \Vert}\]
\end{satz} Der Beweis des Satzes folgt aus der Cauchy-Schwarzschen Ungleichung:
\begin{satz}[Cauchy-Schwarzsche Ungleichung]
Sei $V$ ein $\mathbb{R}$-Vektorraum mit einem Skalarprodukt. Dann gilt für $\vec{v}, \vec{w} \in V$:
\[\vert \langle \vec{v}, \vec{w} \rangle \vert ^{2} \leq \langle \vec{v}, \vec{v} \rangle \cdot \langle \vec{w}, \vec{w} \rangle\]
\end{satz}
\section{Normen}
Nun müssen wir uns näher mit Normen beschäftigen. Wir haben gesehen, dass die Norm eine Abbildung ist, die die drei Eigenschaften Definitheit, Homogenität und die Dreiecksungleichung erfüllen muss. Wir begannen mit der Länge eines Vektors und abstrahierten darauf basierend die Norm. Die Formel für die Länge eines Vektors ist eine spezielle Norm, die sogenannte \textbf{euklidische Norm}. Nun ist aber offensichtlich, dass es weitere Abbildungen auf Vektorräumen geben kann, die die drei Axiome erfüllen - folglich gibt es eine Vielzahl verschiedener Normen, von denen wir einige im Folgenden betrachten wollen.
\begin{definition} Wir betrachten einen Vektor $\vec{v} \in \mathbb{R}^n$.
\begin{enumerate}
\item Die \textbf{Summennorm} oder \textbf{1-Norm} des Vektors ist definiert durch: 
\[\Vert \vec{v} \Vert _{1} = \sum\limits_{i=1}^{n} \vert v_i \vert\]
\item Die \textbf{euklidische Norm} pder \textbf{2-Norm} des Vektors ist definiert durch:
\[\Vert \vec{v} \Vert _{2} = \sqrt{\sum\limits_{i=1}^{n} \vert v_i \vert ^{2}}\]
\item Die \textbf{Maximumsnorm} oder \textbf{$\infty$-Norm} des Vektors ist definiert durch:
\[\Vert \vec{v} \Vert _{\infty} = \max _{i=1, ..., n} \vert v_i \vert\]
\end{enumerate}
\end{definition}
Darauf basierend existiert folgender Satz:
\begin{satz}
Die euklidische Norm $\Vert \vec{v} \Vert _{2} = \sqrt{\sum\limits_{i=1}^{n} v_{i}^{2}}$ und die Maximumsnorm $\Vert \vec{v} \Vert _{\infty} = \max _{i=1, ..., n} \vert v_i \vert$ sind äquivalent. Sie lassen sich gegeneinander mit Konstanten abschätzen.
\[k_1 \cdot \Vert \vec{v} \Vert _{2} < \Vert \vec{v} \Vert _{\infty} < k_2 \cdot \Vert \vec{v} \Vert\]
\end{satz}
Nun greifen wir den Vorlesungsinhalten etwas vor und führen einen weiteren Begriff ein, den wir später gebrauchen werden.
\begin{definition}
Sei $E$ ein reeller Vektorraum. Unter einer \textbf{Metrik} verstehen wir eine Abbildung $d: E \times E \to \mathbb{R}$ mit folgenden Eigenschaften:
\begin{enumerate}
\item $d(\vec{x}, \vec{y}) \geq 0 \text{ und } = 0 \Leftrightarrow \vec{x} = \vec{y}$
\item $d(\vec{x}, \vec{y}) = d(\vec{y}, \vec{x})$
\item $d(\vec{x}, \vec{y}) \leq d(\vec{x}, \vec{z}) + d(\vec{z}, \vec{y})$ (Dreiecksungleichung)
\end{enumerate}
\end{definition}
\begin{note}
Die Wahl des Buchstabens $d$ für die Metrik $d(\vec{v}, \vec{w})$ erklärt, was die Metrik angibt: Den Abstand - die Distanz - zwischen zwei Punkten bzw. Vektoren.
\end{note}
Damit können wir folgenden Satz formulieren:
\begin{satz}
Aus jeder Norm $N$ kann eine Metrik $d_N$ wie folgt abgeleitet werden:
\[d_N (\vec{v}, \vec{w}) := N(\vec{v} - \vec{w})\]
\end{satz}
\pagebreak
\section*{Aufgaben}
\paragraph{Aufgabe 1} Berechnen Sie für die die angegebenen Vektoren jeweils die drei definierten Normen.
\begin{enumerate}
\item $\vec{w_1} = \left( \begin{matrix} 17 \\ 12 \\ 24 \\ 7\end{matrix} \right)$
\item $\vec{w_2} = \left( \begin{matrix} x+3 \\ 12-z \\ \frac{x}{2} \end{matrix} \right), \text{ mit } 5 < x < z$
\item $\vec{w_3} = \left( \begin{matrix} 0 \\ -1 \\ 0 \end{matrix} \right)$
\end{enumerate}
\begin{flushright}
Lösung (folgt)
\end{flushright}
\paragraph{Aufgabe 2} Zeigen Sie, dass die aus der Norm abgeleitete (vermeintliche) Metrik tatsächlich alle drei geforderten Axiome einer Metrik erfüllt.
\begin{flushright}
Lösung (folgt)
\end{flushright}
\paragraph{Aufgabe 3} Beurteilen Sie, inwiefern Skalarprodukt, Norm und Metrik in einem Zusammenhang stehen.
\begin{flushright}
Lösung (folgt)
\end{flushright}
\pagebreak
\part{Einführung in die Analysis mehrerer Veränderlicher}
Nun ist der Koffer gepackt, alle wichtigen Hilfsmittel der linearen Algebra liegen vor, um sich ganz der Analysis zu verschreiben. Ich verzichte auf eine separate Wiederholung der Konzepte der Analysis I und beginne direkt damit, beides ineinander zu verweben, auch, um deutlich zu machen, dass Analysis II die Analysis I im Wesentlichen nur ergänzt.
\section{Folgen, Reihen und Konvergenz}
Steigen wir ein, indem wir uns die Definition von Folgen zurück ins Gedächtnis rufen.
\begin{definition}
Eine Folge ist eine endliche oder nicht-endliche Auflistung von Zahlen, die in aufsteigender Riehenfolge lückenlos durchnummeriert sind. Wir schreiben eine Folge $a_n$ als $(a_{n}) = a_1, a_2, ..., a_n, a_n+1, ..., a_m$.
\end{definition}
In der Analyis I haben wir Folgen auf der Menge der reellen Zahlen betrachtet. Nun lassen sich jedoch auch Folgen von Vektoren betrachten.
\begin{example}
\[(a_n) = \left( \begin{matrix}\frac{1}{n} \\ \frac{1}{n}\end{matrix}\right), n \in \mathbb{N}\]
\end{example}
Über Folgen können wir eine Reihe von Aussagen treffen. Eine davon ist eine Beschreibung des Verhaltens sehr großer Folgenglieder, das Grenzwertverhalten.
\begin{definition}
Sei eine Folge $(a_n)$ und außerdem eine Zahl $g \in \mathbb{R}$ gegeben. $g$ heißt \textbf{Grenzwert} von $(a_n)$, falls $\forall \epsilon > 0 \exists N \in \mathbb{N}$ mit:
\[\vert a_n - g \vert < \epsilon \quad \forall n \geq N\]
Eine Folge hat höchstens einen Grenzwert. Existiert ein Grenzwert, so \textbf{konvergiert} die Folge.
\end{definition}
Mit unseren Definitionen aus der linearen Algebra können wir die Definition der Konvergenz auf Folgen von Vektoren ausweiten.
\begin{definition}
Gegeben sei eine Folge von Vektoren $(a_n) \in \mathbb{R}^{n}$ und eine Metrik $d$. Dann konvergiert $(a_n)$ gegen einen Grenzwert $g \in \mathbb{R}^{n}$, falls gilt: 
\[\forall \epsilon > 0 \exists N \in \mathbb{N} \quad \forall n > N: d(g, a_n) < \epsilon\]
\end{definition}
Nun werden wir noch einen Schritt komplizierter und betrachten die Konvergenz von Funktionen.
\begin{definition}
Sei $f: X \subset \mathbb{R}^{n} \to \mathbb{R}^{m}$ eine Funktion und $a \in X$. Wir nennen $L_a \in R^{m}$ Grenzwert von $f$ bezüglich der Annäherung von $x$ an $a$, falls für jede konvergente Folge $x_n \to a$ die Folge $f(x_n)$ gegen $L_a$ konvergiert. Dies lässt sich schreiben als \[
\lim _{x \to a} f(x) = L_a \]
\end{definition}
\begin{note}
Wir betrachten hier bereits eine mehrdimensionale Funktion. Zunächst konstruieren wir eine Folge $(x_n)$ aus dem Definitionsbereich dieser Funktion und betrachten ihr Grenzverhalten. Konvergiert jede erdenkliche Folge gegen $a$, so konvergiert auch die Folge nach Anwendung der Funktion $f$, also $f(x_n)$. Dieser Grenzwert ist selbstverständlich im Allgemeinen nicht $a$, sondern wird von uns mit $L_a$ für {\glqq}Limes{\grqq} bezeichnet. 
\end{note}
\section{Stetigkeit}
Besinnen wir uns zurück auf das Konzept der Stetigkeit. Als ganz profane und rudimentäre Erklärung sagten wir, dass eine Funktion genau dann stetig ist, wenn wir beim Zeichnen ihres Graphen den Stift nicht absetzen müssen, also eine durchgezogene Linie ohne Sprünge zu Papier bringen können. Wir ergänzten und formalisierten diese Definition zu der folgenden:
\begin{definition}[Epsilon-Delta-Kriterium]
Eine Funktion $f$ ist genau dann stetig in $x_0$, wenn \[
\forall \epsilon > 0 \quad \exists \delta > 0 \quad \forall x \in D_f: \vert x - x_0 \vert < \delta \Rightarrow \vert f(x) - f(x_0) \vert < \epsilon \] gilt.
\end{definition}
Eine weitere, andere Definition nutzt die Grenzwertbildung aus.
\begin{definition}
Eine Funktion $f$ heißt stetig in $x_0$, falls 
\[\lim _{x \to x_0} f(x) = f(x_0)\] gilt.
\end{definition}
\begin{note}
Das heißt: Existiert für jedes $x$, dass ich gegen $x_0$ laufen lasse, ein Grenzwert und stimmt dieser mit dem Funktionswert von $x_0$, also $f(x_0)$ überein, dann ist diese Funktion stetig in $x_0$.
\end{note}
Eine Funktion insgesamt ist dann stetig, wenn sie für alle Werte ihres Definitionsbereiches stetig ist. 
\section{Differenzierbarkeit}
Stetig wird es schwerer, ebenso aber natürlich auch spannender. Nun sind wir bereit, Funktionen abzuleiten und die fundamentalen Konzepte der Analysis anzuwenden. Betrachten wir zunächst den Differentialquotienten aus der Analysis I:
\begin{definition}
Die lokale Änderungsrate einer Funktion $f: \mathbb{R} \to \mathbb{R}$ wird durch den Differentialquotienten
\[f'(x) = \lim _{x \to x_0} \frac{f(x) - f(x_0)}{x - x_0}\] angegeben.
\end{definition}
Nun wollen wir diese Definition auf mehrdimensionale Funktionen erweitern. Dafür werden wir uns zunächst bewusst, dass wir einen weiteren Parameter benötigen: Einen Vektor, der angibt, in welche Richtung wir die Ableitung bestimmen wollen.
\begin{definition}
Sei $f: U \to \mathbb{R}$ eine Funktion. Für einen Vektor $\vec{h} \in \mathbb{R}^{n}$ und einen Punkt $a \in U$ heißt der Grenzwert
\[\delta _{n} f(a) := \lim _{t \to o} \frac{f(a + t\vec{h}) - f(a)}{t}\] die \textbf{Richtungsableitung} von $f$ am Punkt $a$ in Richtung $\vec{h}$.
\end{definition}
Ein Speziallfall dessen ist die \textbf{partielle Ableitung} mit einem Einheitsvektoren als Richtungsangabe.
\begin{definition}
Für die Standardbasisvektoren $\vec{e_i}$ nennen wir 
\[\frac{\delta f(a)}{\delta x_i} = \delta _{e_i} f(a) = \lim _{t \to 0} \frac{f(a + t\vec{e_i}) - f(a)}{t}\]
die \textbf{partielle Ableitung} von $f$ in $a$ nach $\vec{x_i}$.
\end{definition}
Darauf aufbauend definieren wir nun die partielle Differenzierbarkeit.
\begin{definition}
Eine Funktion $f: U \to \mathbb{R}$ heißt partiell differenzierbar im  Punkt $a \in U$, falls die partiellen Ableitungen
\[\frac{\delta f(a)}{\delta x_1}, ..., \frac{\delta f(a)}{\delta x_n}\]
existieren und stetig sind. In diesem Fall nennen wir die Matrix \[
df(a) := \left( \begin{matrix}\frac{\delta f(a)}{\delta x_1} & ... & \frac{\delta f(a)}{\delta x_n}\end{matrix}\right)
\]
das \textbf{Differential} von $f$ im Punkt $a$.
\end{definition}
Dasselbe auf dem Kopf ist die Definition des Gradienten:
\begin{definition}
Der Vektor \[\nabla f(a) := \left( \begin{matrix}\frac{\delta f(a)}{\delta x_1} \\ ... \\ \frac{\delta f(a)}{\delta x_n}\end{matrix}\right)\]
wird als \textbf{Gradient} bezeichnet. Ferner gilt:\[
df(a) \cdot h = \langle \nabla f(a), h \rangle\]
\end{definition}
Für das Differential gelten zudem eine Reihe von Eigenschaften:
\begin{satz}
Für das Differential einer differenzierbaren Funktion $f: U \to \mathbb{R}$ gilt für alle $a \in U$:
\begin{itemize}
\item $df(a)(h) := df(a) \cdot h$ - Dies ist eine lineare Abbildung von $\mathbb{R}^n \to \mathbb{R}$.
\item $df(a)\cdot h = \delta _n f(a)$ 
\item $d(f \cdot g) = g(a)d(f) + f(a)dg$
\item $d(f+g) = df + dg$ 
\end{itemize}
\end{satz}
Dies ist nun genug Handwerkszeug, um die erste Ableitung mehrdimensionaler Funktionen zu berechnen. Für bestimmte Fragen, wie beispielsweise nach Extrema, wird ebenfalls die zweite Ableitung verlangt. Oben haben wir eine Funktion in jede Dimension (also nach jeder Variable) abgeleitet und einen Vektor (den Gradienten) erhalten. Wollen wir nun die zweite Ableitung bestimmen, müssen wir diesen Vektor ableiten. 
\begin{definition}
Sei $U \subset \mathbb{R}^n$ offen und $f: U \to \mathbb{R}$ eine zweimal stetig differenzierbare Funktion. Unter der \textbf{Hesseschen Matrix} von $f$ im Punkt $x \in U$ versteht man die $n \times n$-Matrix
\[(\text{Hess} f)(x) = \left( \begin{matrix} \frac{\delta}{\delta x_1} \frac{\delta}{\delta x_1} & ... & \frac{\delta}{\delta x_1}\frac{\delta}{\delta x_n} \\
... & ... & ... \\
\frac{\delta}{\delta x_n}\frac{\delta}{\delta x_1} & ... & \frac{\delta}{\delta x_n}\frac{\delta}{\delta x_n} \end{matrix}\right)\]
Diese Matrix ist nach dem Satz von Schwarz symmetrisch.
\end{definition}
\begin{note}
Die Reihenfolge, nach welcher Variable zuerst abgeleitet wird, spielt folglich keine Rolle. Die Annahme, man können hier die Ableitungen miteinander multiplizieren, ist falsch. Viel mehr handelt es sich bei den Delta-Brüchen um eine Kennzeichnung, dass hier eine Ableitung gebildet wurde.
\end{note}
\section{Approximation}
In der Analysis I haben wir uns bereits mit Approximationen beschäftigt. Damit bezeichnen wir das Verfahren, eine komplizierte Funktion durch eine einfachere -- häufig lineare oder polynomiale -- anzunähern. Diese Annäherungen sind immer bis auf einen bestimmten Fehler genau und genügen so vielen Fragestellungen aus der Anwendung.
Ein prominentes Beispiel ist die \textbf{Taylor-Approximation}, die wir an dieser Stelle kurz wiederholen wollen.
\begin{definition} Das $n$-te \textbf{Taylorpolynom} von $f$ an der Entwicklungsstelle $a$ ist definiert durch:
\[T_n f(x, a) := \sum\limits _{k=0}^{n} \frac{f^{k}(a)}{k!} \cdot (x-a)^k\]
Der Genauigkeit halber wird ein Restglied $R_n f(x,a)$ hinzu addiert.
\end{definition}


\end{document}